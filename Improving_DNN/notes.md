# Notes

### November 17, 2019 (started)
Had a lot of chores to do (as well as picking up some stuff I left at the apartment) so I didn't get as much time in as I wanted today. But that's alright, I've been going past time a lot the past few days :)

#### Accomplished Today
- Learned about
    + Strategies for reducing bias and variance with NNs
        * variance can be reduced with regularization and increasing the amount of training data you have
        * bias can be reduced by increasing the complexity of your NN
    + Methods for regularization
        * L1 and L2 norms
        * Dropout regularization
    + Methods for speeding up training
        * Exploding and dissapearing weights (due to the depth of nets)
            - Reducing the variance in the initial set of parameters
        * Normalization (to help gradient descent behave)
    + Using numerical approximation of gradients to check for bugs in your backwards propogation
- Completed all the lectures for week 1 of the course
#####2hrs

#### Goals for Next Time
- Complete the quiz
- Complete the practice problems
- Complete week 1!
